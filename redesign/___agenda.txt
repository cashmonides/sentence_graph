/////

use this for issues

SHORT TERM

- allowed is not controling drop down parameters
    - drop/non-drop
    - number of dummy options
    - swap

- example of wanted function behavior for drop/non-drop
- ['subject', 'verb', conjunction', 'verb'] -> ['drop', 'non-drop', 'non-drop', 'drop']
- the subject and second verb become drop downs and the first verb and conjunction do not
        
- drop/non-drop in detail
    - prob. should operate on role so it's language independent
    - at some point we'll need to reorder and scramble things in Latin so we shouldn't code ourselves into a corner



SHORT TERM MIDTERM

- 2. level-based issues

- make a display preferences dictionary (adapt from previous version with ratios and ranges)
    - number of dummy lexemes
    - upper or lower case for each language
    - drop down path preference
    - which components are non-drops and which components are drops
    - which language to which language
    - dashes or no dashes
    - none optionality (that's more of a noun-based thing anyway so maybe skip)
- make a set of allowed parameters
    - allowed conjunction
    - allowed lexemes
    - allowed voice
    - allowed person/number


- import and adapt range-reading functions from previous incarnation





3. time distinctions

- make relative and absolute time properly distinguished backstage

4. display issues
- write a terminology display dictionary for all languages
    - key: value
    - preterite: past
    - imperfect subjunctive: same time subjunctive 2nd degree
    - teacher should be able to update at a fine-grained level

5. other types of data
- try sending zoological (taxonomy) data to drop downs


6. ambiguity
- ambiguity resolution
 - two distinct answers with same text
        - ruit (perfect) = ruit (present)
        - leones (nom) = leones (acc)
        - he verbs = more than one path in english
        - lexeme-level phenomenon
 - impossible to determine correct answer with information given (down the road)
        - leones amant duces
        - sentence-level phenominon

7. testing

- run a bunch of tests, looking for semantic nonsense just in verbs
    - of the sort: "he will be feared that he will attack"

8. adding more lexemes

- add a bunch of verb lexemes

- add more conjunctions to conjunction library
    
9. make vocabulary cheat sheets

- make vocabulary cheat sheets

LONG TERM MIDTERM AGENDA

1. drop-down work
- investigate lingering drop down bugs
    - maybe use a mouse-over functionality

4. display issues
- write a dash-removal function
    - adapt from previous incarnation

7. testing
- testing
    - make a button/drop-down/slider to set level (just for testing)

- testing dummy lexemes/drop downs
    - build in defensiveness, if not enough lexemes exist, then just skip those without crashing


10. integration
- integrate into quiz and profile


LONGER TERM

- lexeme is always in english in the drop downs, should also be available in latin


- somehow add morphological data to drop downs 
    - lexeme, principal part, infix, ending
    - attack, oppugnav, era, s -> oppugnav-era-s
    - goal: nested drop down can be used as a latin morphology trainer


////////




randomly generate maximal templates
    aS S gen-S a-gen-S V a-O O with-abl adj-with-abl prep-phrase

randomly fill whole template

remove certain parts of template (replace with none)

add nouns

add none display

add adjectives







/////////////////


DONE AND OLDER STUFF BELOW



- fix the independent subjunctive bugs (done)

- switch past present future to prior, simultaneous, subsequent in conjunction library (done)

- include conditional type as a clause type (pres ctf, etc.) (done, but was it done in a good way?)

- include independent subjunctive type as a clause type (present deliberative etc.)
(done. but there's one clause type for all independent subjunctives)

- make a conjunction object (seems to be done)

-????: use our dummy lexicon to produce a display
    - dummy lexicon is var testing_kernels in testing_kernel_library

- rebuild lexicon

- plug in our lexicon to the stream

- decide if we want to add sequence property to conditionals
(only an issue to distinguish between flv and pres ctf and e.g. to tell whether we want pluperf subj or perf subj)



What has happened and our plans:




PART 1

STAGE -1
- 1: decide on design rules
- 2: decide on object types

STAGE 0:
- 1: produce blank kernels
- 2: add determistic properties

STAGE 1
- 1: add random properties
- 2: add sequence
- 3: add person and number

(we are here)

STAGE 1.5
- 1: display
- 2: check to make sure we have enough information to make a quiz from this
explanation from Akiva:
i.e. we want to ask about all properties and we want to ask about part of speech
so we just want to make sure that we have all that information and it's easy to access
(we don't need to make the quiz obviously)
What part of speech is the highlighted word?
Is the highlighted word transitive or intransitive?
Is the highlighted word active of passive?


STAGE 2
general note: don't add nouns yet!!!
- 1: instead, feed K C K into our pipeline
question from Dan to Akiva: are we doing this?
- 2: and plug the end result V(with properties) C(with properties) V(with properties)
into a function that inflects English, Latin and SSSLatin
- 3: we already have such functions, we should pull them out into their own files
(inflect_verb.js or something similar) and adapt them as necessary


STAGE 3
- 1: reflect on the process so far
- 2: make any redesign decisions

End of PART 1

PART 2

STAGE 4
- 1: add lexeme choice
- 2: rebuild our verb lexicon

STAGE 5
note: in this stage we have a new MVP
question from Dan: Wasn't stage 4 intended for the same MVP?
- 1: produce sentences of the form:
"you love because we shout"
"he will attack if they shout"
"if they shout, he will attack"
with enough information to make a quiz on all properties, including clause type

End of PART 2



MAKE DROP DOWN FUNCTIONALITY IN BOTH DIRECTIONS






PART 3

STAGE 6 (and maybe more)
- add nouns

...

End of PART 3

(the unknown beyond)

END

Notes:
Why do so much with verbs before adding nouns?
Isn't it descending into the messy reality prematurely?
Shouldn't we just generate purely abstract kernels
with S and O and adjectives first?

Well, maybe. But we have the inflect verb functions pretty well developed
already and it won't take long to chain them up into the pipeline.
The advantage of doing this now is that we will see all the strange things
and weird linguistic realities and bugs and design issues and pain points.
We might learn a great deal and it won't take too long.